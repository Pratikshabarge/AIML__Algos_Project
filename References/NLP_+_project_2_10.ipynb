{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "NLP + project-2.10.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pratikshabarge/AIML__Algos_Project/blob/main/References/NLP_%2B_project_2_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzogi0CCHNja"
      },
      "source": [
        "import nltk\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import numpy as np\n",
        "import random\n",
        "import string\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPY-0PTLHUuM"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qgkcWgiQhd6"
      },
      "source": [
        "# path = '/content/drive/MyDrive/Colab Notebooks/Machine learning3.1.txt'\n",
        "# file1 = open(path, 'r')\n",
        "\n",
        "# raw = file1.read()\n",
        "# raw"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0uKnv9X6jki"
      },
      "source": [
        "raw = 'Hi. Hi there. Hello. Hello there. Hello, I am fine buddy. Hi, I am fine buddy.\\n\\nI am doing fine, may I know your query.\\nI am doin fine, may I know your query.  \\nI am fine, may I know your query.\\nWell then , lets get on with the work!.\\nSo whats up at the workfront.\\n\\n\\nOh great, so you have come at the right place to process your dataset.\\n\\n\\n\\nOh so lets solve your problem with the dataset\\n\\nWonderful , but can you tell me which specific machine learning algorithm type, classification, regression or deep learning?\\n\\nWonderful , but can you tell me which specific ML algorithm you would like to run, classification or regression or deep learning? \\n\\nWonderful , but can you tell me which specific Regression algorithm you would like to run?\\n\\nWonderful , but can you tell me which specific Classification algorithm would you like to run?\\n\\nWonderful , but can you tell me which specific deep learning algorithm you would like to run?\\n\\nWonderful, now can you tell me which specific algorithm you would like to run?\\n\\n\\n\\nGreat , So which classification algorithm?\\n\\n\\nGreat, So which regression algorithm?\\n\\nGreat, So which deep learning algorithm?'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHgzgIoE6kGX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJP-yp86HiTw"
      },
      "source": [
        "# with open('Machine learning3.1.txt', 'r') as f :"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEgRnUDjPsd-"
      },
      "source": [
        "# print('/content/drive/MyDrive/Colab Notebooks/Machine learning3.1.txt contains:')\n",
        "# !cat /content/drive/MyDrive/Colab Notebooks/Machine learning3.1.txt\n",
        "# !ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKiKU8LbHNkG"
      },
      "source": [
        "raw=raw.lower()# converts to lowercase"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsObqf2QHNkI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afe8d4a2-fdee-4298-d027-b0a056db64c2"
      },
      "source": [
        "nltk.download('punkt')\n",
        "sent_tokens = nltk.sent_tokenize(raw)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0nLBQmAHNkK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "771690da-d4b6-4a94-ab37-9e72796fefa1"
      },
      "source": [
        "sent_tokens[:2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hi.', 'hi there.']"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8nJXYnKHNkN"
      },
      "source": [
        "word_tokens = nltk.word_tokenize(raw)# converts to list of words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJyfQD6CHNkP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6000c05-8468-4030-d805-dfdc7de4f5b3"
      },
      "source": [
        "word_tokens[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hi', '.', 'hi', 'there', '.']"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcqnjCl8HNkS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76ceb464-86f4-4e57-97fd-e121304f197e"
      },
      "source": [
        "sent_tokens[:3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hi.', 'hi there.', 'hello.']"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8c9_B3_HNkV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68757ae1-fd08-4afb-c6ab-527e79691a65"
      },
      "source": [
        "word_tokens[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hi', '.', 'hi', 'there', '.']"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_nu-EYEHNkX"
      },
      "source": [
        "lemmer = nltk.stem.WordNetLemmatizer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnUrDm1yHNkY"
      },
      "source": [
        "def LemTokens(tokens):\n",
        "    return [lemmer.lemmatize(token) for token in tokens]\n",
        "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8E5_R_mGHNka"
      },
      "source": [
        "def LemNormalize(text):\n",
        "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E208x4YsHNkb"
      },
      "source": [
        "# GREETING_INPUTS = (\"hello\", \"hi\", \"greetings\", \"sup\", \"what's up\",\"hey\",)\n",
        "# GREETING_RESPONSES = [\"hi\", \"hey\",  \"hi there\", \"hello\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StwFR8viHNkc"
      },
      "source": [
        "import re\n",
        "REGRESSION_INPUTS = ['Linear Regression', 'Decision Tree Regression' , 'Support Vector Regression ','Lasso Regression','Ridge Regression',\n",
        "                      'Random Forest Regression']\n",
        "\n",
        "CLASSIFICATION_INPUTS  = ['Logistic Regression','Naive Bayes','Stochastic Gradient Descent','K-Nearest Neighbours',\n",
        "                         'Decision Tree classifier','Decision Tree Classification', 'Random Forest classifier',\n",
        "                          'Random Forest Classification', 'Support Vector Machine' , 'Support Vector Classifier' , 'Support Vector Classification']\n",
        "\n",
        "DEEPLEARNING_INPUTS = ['Convolutional Neural Network',  'CNN'  ,'Long Short Term Memory Networks (LSTMs)' ,  'LSTM'\n",
        "                        'Recurrent Neural Networks (RNNs)', 'BERT', 'Transfer Learning']\n",
        "\n",
        "BYE_INPUTS = ['bye' , 'see ya' , 'good bye' , 'good night' , 'take care', 'good day']\n",
        "BYE_RESPONSES = [ 'Bye there' , 'bbyyeee' , 'See Ya' , 'Take Care']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Vihrao7HNkf"
      },
      "source": [
        "# def greeting(sentence):\n",
        "#     \"\"\"If user's input is a greeting, return a greeting response\"\"\"\n",
        "#     for word in sentence.split():\n",
        "#         if word.lower() in GREETING_INPUTS:\n",
        "#             return random.choice(GREETING_RESPONSES)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxwWHKpcHNkg"
      },
      "source": [
        "def byebye(sentence):\n",
        "    \"\"\"If user's input is a greeting, return a greeting response\"\"\"\n",
        "    for word in sentence.split():\n",
        "        if word.lower() in BYE_INPUTS:\n",
        "            return random.choice(BYE_RESPONSES)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmXO5ydXHNkh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5797c89-2433-48f2-cfd2-96f804bb672a"
      },
      "source": [
        "def regAlgorithm(sentence):\n",
        "#     r = re.compile(\".*{}.*\" .format(sentence))\n",
        "#     matchedStr = str(filter(r.match, REGRESSION_INPUTS)) # Read Note below\n",
        "#     print(matchedStr)\n",
        "    count = 1\n",
        "    \n",
        "    for pattern in REGRESSION_INPUTS:\n",
        "        \n",
        "        if count <= len(REGRESSION_INPUTS):\n",
        "        \n",
        "            if re.search(pattern.lower(), sentence):\n",
        "\n",
        "                    global typeMLalgo\n",
        "                    typeMLalgo = pattern\n",
        "                    Robo_response =  pattern + \" thats wonderful, Now may I know the target label for your dataset\"\n",
        "                    return Robo_response\n",
        "                    \n",
        "#             else:\n",
        "#                     if count == len(REGRESSION_INPUTS):\n",
        "#                           return \"Could you be more specific!\" \n",
        "                        \n",
        "                    count = count+1\n",
        "                    \n",
        "print(\"length of regression list is: \" ,len(REGRESSION_INPUTS))  \n",
        "# print(\"the type regression is : %s\" %(typeMLalgo))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of regression list is:  6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zD6EfEbmHNkk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1f7cc15-6cbb-4672-fcd0-28398977ca04"
      },
      "source": [
        "def claAlgorithm(sentence):\n",
        "#     r = re.compile(\".*{}.*\" .format(sentence))\n",
        "#     matchedStr = str(filter(r.match, REGRESSION_INPUTS)) # Read Note below\n",
        "#     print(matchedStr)\n",
        "    count = 1\n",
        "    for pattern in CLASSIFICATION_INPUTS:\n",
        "        \n",
        "        if count <= len(CLASSIFICATION_INPUTS):\n",
        "        \n",
        "            if re.search(pattern.lower(), sentence):\n",
        "\n",
        "                    global typeMLalgo\n",
        "                    typeMLalgo = pattern\n",
        "                \n",
        "                    Robo_response =  pattern +  \" thats wonderful, Now may I know the target label for your dataset\"\n",
        "                    return Robo_response\n",
        "                    \n",
        "#             else:\n",
        "#                     if count == len(REGRESSION_INPUTS):\n",
        "#                           return \"Could you be more specific!\" \n",
        "                        \n",
        "                    count = count+1\n",
        "                    \n",
        "print(\"length of classification list is: \" ,len(CLASSIFICATION_INPUTS))  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of classification list is:  11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzHyxreXHNkm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6ac2014-0a3b-4683-a328-c933b61fcaf2"
      },
      "source": [
        "def deepAlgorithm(sentence):\n",
        "#     r = re.compile(\".*{}.*\" .format(sentence))\n",
        "#     matchedStr = str(filter(r.match, REGRESSION_INPUTS)) # Read Note below\n",
        "#     print(matchedStr)\n",
        "    count = 1\n",
        "    for pattern in DEEPLEARNING_INPUTS:\n",
        "        \n",
        "        if count <= len(DEEPLEARNING_INPUTS):\n",
        "        \n",
        "            if re.search(pattern.lower(), sentence):\n",
        "                    \n",
        "                    global typeMLAlgo\n",
        "                    typeMLalgo = pattern\n",
        "\n",
        "                    Robo_response = pattern +  \" thats wonderful, Now may I know the target label for your dataset\"\n",
        "                    return Robo_response\n",
        "                    \n",
        "#             else:\n",
        "#                     if count == len(REGRESSION_INPUTS):\n",
        "#                           return \"Could you be more specific!\" \n",
        "                        \n",
        "                    count = count+1\n",
        "                    \n",
        "print(\"length of regression list is: \" ,len(DEEPLEARNING_INPUTS))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of regression list is:  6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_2eY5XlHNkp"
      },
      "source": [
        "def response(user_response):\n",
        "    robo_response=''\n",
        "    TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')\n",
        "    tfidf = TfidfVec.fit_transform(sent_tokens)\n",
        "    vals = cosine_similarity(tfidf[-1], tfidf)\n",
        "    idx=vals.argsort()[0][-2]\n",
        "    flat = vals.flatten()\n",
        "    flat.sort()\n",
        "    req_tfidf = flat[-2]\n",
        "    if(req_tfidf==0):\n",
        "        robo_response=robo_response+\"I am sorry! I don't understand you, be more elaborative\"\n",
        "        return robo_response\n",
        "    else:\n",
        "        robo_response = robo_response+sent_tokens[idx]\n",
        "        return robo_response"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zr8cmwSzHNkq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bdd458a-b127-4e27-e8e6-cd57af88964e"
      },
      "source": [
        "\n",
        "flag=True\n",
        "regAlgo = False\n",
        "claAlgo = False\n",
        "deepAlgo = False\n",
        "linkFlag = False\n",
        "\n",
        "nltk.download('wordnet')\n",
        "print(\"ROBO: My name is Robo. I will answer your queries about Chatbots. If you want to exit, type Bye!\")\n",
        "\n",
        "while(flag==True):\n",
        "    \n",
        "    user_response = input()\n",
        "    \n",
        "    user_response=user_response.lower()\n",
        "    \n",
        "#     if(user_response==r'.*bye.*'):\n",
        "#         flag=False\n",
        "#         print(\"ROBO: Bye! take care..\") \n",
        "    \n",
        "    \n",
        "    if(user_response=='thanks' or user_response=='thank you' ):\n",
        "#             flag=False\n",
        "            print(\"ROBO: You are welcome..\")\n",
        "       \n",
        "            \n",
        "    \n",
        "#             if(greeting(user_response)!=None):\n",
        "                \n",
        "#                 print(\"ROBO: \"+greeting(user_response))\n",
        "        \n",
        "            \n",
        "    elif(linkFlag == True):\n",
        "\n",
        "        link_use_resp = user_response\n",
        "\n",
        "        pattern_link = r'https://.*'\n",
        "        count_link = 1\n",
        "\n",
        "        for final_link in link_use_resp.split():\n",
        "\n",
        "                if re.search(pattern_link, final_link):\n",
        "\n",
        "                    print(\"ROBO: Thanks for the link {}, Now please relax and wait for result\" .format(final_link))\n",
        "                    linkFlag = False\n",
        "                    break\n",
        "                else:\n",
        "\n",
        "                    if (count_link == len(link_use_resp.split())):\n",
        "                        print(\"ROBO: please provide the correct link\")\n",
        "                        break\n",
        "                    else:\n",
        "                        count_link = count_link + 1                   \n",
        "\n",
        "\n",
        "\n",
        "    elif(regAlgo == True):\n",
        "\n",
        "            w = []\n",
        "\n",
        "            for word in user_response.split():\n",
        "\n",
        "                w.append(word)\n",
        "\n",
        "                last_word_label = w[len(w)-1]\n",
        "\n",
        "\n",
        "            print(\"ROBO: So '{}' would be your target/label , seems good, now can you provide me link for the dataset\" \n",
        "                  .format(last_word_label)) \n",
        "\n",
        "            regAlgo = False\n",
        "\n",
        "            linkFlag = True \n",
        "\n",
        "\n",
        "\n",
        "    elif(claAlgo == True):\n",
        "\n",
        "            w = []\n",
        "\n",
        "            for word in user_response.split():\n",
        "\n",
        "                w.append(word)\n",
        "\n",
        "                last_word_label = w[len(w)-1]\n",
        "\n",
        "\n",
        "            print(\"ROBO: So '{}' would be your target/label , seems good, now can you provide me link for the dataset\" \n",
        "                  .format(last_word_label)) \n",
        "\n",
        "            claAlgo = False\n",
        "\n",
        "            linkFlag = True\n",
        "\n",
        "\n",
        "\n",
        "    elif(deepAlgo == True):\n",
        "\n",
        "            w = []\n",
        "\n",
        "            for word in user_response.split():\n",
        "\n",
        "                w.append(word)\n",
        "\n",
        "                last_word_label = w[len(w)-1]\n",
        "\n",
        "\n",
        "            print(\"ROBO: So  '{}' would be your target/label , seems good, now can you provide me link for the dataset\" \n",
        "                  .format(last_word_label)) \n",
        "\n",
        "            deepAlgo = False\n",
        "\n",
        "            linkFlag = True \n",
        "\n",
        "\n",
        "\n",
        "    elif(regAlgorithm(user_response) != None) :                \n",
        "\n",
        "\n",
        "            robo_response = regAlgorithm(user_response)\n",
        "            regAlgo = True\n",
        "\n",
        "\n",
        "            print(\"ROBO: \", robo_response)\n",
        "\n",
        "\n",
        "#                     sent_tokens.append(user_response)\n",
        "\n",
        "#                     word_tokens=word_tokens + nltk.word_tokenize(user_response)\n",
        "\n",
        "#                     final_words=list(set(word_tokens))\n",
        "\n",
        "#                     print(\"ROBO: \",end=\"\")\n",
        "\n",
        "\n",
        "\n",
        "#                     sent_tokens.remove(user_response)\n",
        "\n",
        "    elif(claAlgorithm(user_response) != None) :                \n",
        "\n",
        "\n",
        "            robo_response = claAlgorithm(user_response)\n",
        "            claAlgo = True\n",
        "\n",
        "\n",
        "            print(\"ROBO: \", robo_response)\n",
        "\n",
        "    elif(deepAlgorithm(user_response) != None) :                \n",
        "\n",
        "\n",
        "            robo_response = deepAlgorithm(user_response)\n",
        "            deepAlgo = True\n",
        "\n",
        "\n",
        "            print(\"ROBO: \", robo_response)\n",
        "            \n",
        "    elif(byebye(user_response) != None) :                \n",
        "\n",
        "\n",
        "            robo_response = byebye(user_response)\n",
        "            flag = False\n",
        "\n",
        "\n",
        "            print(\"ROBO: \", robo_response)\n",
        "\n",
        "    else:    \n",
        "\n",
        "            sent_tokens.append(user_response)\n",
        "\n",
        "            word_tokens=word_tokens+nltk.word_tokenize(user_response)\n",
        "\n",
        "            final_words=list(set(word_tokens))\n",
        "\n",
        "            print(\"ROBO: \",end=\"\")\n",
        "\n",
        "            print(response(user_response))\n",
        "\n",
        "            sent_tokens.remove(user_response)\n",
        "          \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "ROBO: My name is Robo. I will answer your queries about Chatbots. If you want to exit, type Bye!\n",
            "hi\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROBO: hi there.\n",
            "linear regression\n",
            "ROBO:  Linear Regression thats wonderful, Now may I know the target label for your dataset\n",
            "medv\n",
            "ROBO: So 'medv' would be your target/label , seems good, now can you provide me link for the dataset\n",
            "https://raw.githubusercontent.com/vaksakalli/datasets/master/boston_housing.csv\n",
            "ROBO: Thanks for the link https://raw.githubusercontent.com/vaksakalli/datasets/master/boston_housing.csv, Now please relax and wait for result\n",
            "bye\n",
            "ROBO:  See Ya\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxTMpR9BHNku"
      },
      "source": [
        "# x for x in list if r.match(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMdd2kqFHNku",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "260291c6-547f-43dc-e678-943271746a78"
      },
      "source": [
        "print(last_word_label)\n",
        "print(final_link)\n",
        "print(typeMLalgo)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "medv\n",
            "https://raw.githubusercontent.com/vaksakalli/datasets/master/boston_housing.csv\n",
            "Linear Regression\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loANKkuTeeHP"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "regModelFlag = False\n",
        "claModelFlag = False\n",
        "\n",
        "if (typeMLalgo == 'Linear Regression' or  typeMLalgo == 'Decision Tree Regression' or  typeMLalgo == 'Support Vector Regression ' or\n",
        "    typeMLalgo == 'Lasso Regression' or   typeMLalgo == 'Ridge Regression' or   typeMLalgo == 'Random Forest Regression'):\n",
        "  \n",
        "    from sklearn.linear_model import LinearRegression\n",
        "    linMod = LinearRegression()\n",
        "    from sklearn.svm import SVR\n",
        "    svrModel = SVR()\n",
        "    from sklearn.ensemble import RandomForestRegressor\n",
        "    rfrModel = RandomForestRegressor()\n",
        "    from sklearn.tree import DecisionTreeRegressor\n",
        "    dtrModel = DecisionTreeRegressor(max_depth=5,min_samples_leaf=3)\n",
        "    \n",
        "    # print(\"regression : %s\" %(typeRegression))\n",
        "    regModelFlag = True\n",
        "\n",
        "elif (typeMLalgo == 'Logistic Regression'  or typeMLalgo == 'Naive Bayes' or  typeMLalgo =='Stochastic Gradient Descent' or\n",
        "     typeMLalgo == 'K-Nearest Neighbours'or typeMLalgo ==  'Decision Tree classifier' or typeMLalgo == 'Decision Tree Classification' or\n",
        "     typeMLalgo == 'Random Forest classifier'or typeMLalgo == 'Random Forest Classification' or typeMLalgo == 'Support Vector Machine' ):\n",
        "     \n",
        "     from sklearn.svm import SVC\n",
        "    #  grid_param = {'C': [0.1, 1, 10, 100, 1000], \n",
        "    #           'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
        "    #           'kernel': ['linear']}\n",
        "     svcModel = SVC()\n",
        "    #  grid_svc = GridSearchCV(SVC(), grid_param, refit = True, verbose=3)\n",
        "    #  grid_svc.fit(X_train, y_train)\n",
        "    #  grid_svc.fit(X_train, y_train)\n",
        "\n",
        "     \n",
        "     from sklearn.linear_model import SGDClassifier\n",
        "     sgdModel = SGDClassifier()\n",
        "     from sklearn.neighbors import KNeighborsClassifier\n",
        "     knnModel = KNeighborsClassifier(n_neighbors = 5)\n",
        "     from sklearn.naive_bayes import GaussianNB\n",
        "     naiveModel = GaussianNB()\n",
        "     from sklearn.tree import DecisionTreeClassifier\n",
        "     dtcModel = DecisionTreeClassifier()\n",
        "     from sklearn.ensemble import RandomForestClassifier\n",
        "     rfcModel = RandomForestClassifier()\n",
        "     from sklearn.linear_model import LogisticRegression\n",
        "     logModel = LogisticRegression()\n",
        "\n",
        "     claModelFlag = True\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NDvD3gEbrIj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "av8q4U0khvsx"
      },
      "source": [
        "# data =   \"https://raw.githubusercontent.com/vaksakalli/datasets/master/boston_housing.csv\"\n",
        "# data2 =  \"https://docs.google.com/spreadsheets/d/1IhrGlblABPTkmxs2nyFdZdbWWgQU4XN6pnC6LLmqLUc/edit?usp=sharing\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qdokXO25dgQ"
      },
      "source": [
        "# !gdown --id \"1IhrGlblABPTkmxs2nyFdZdbWWgQU4XN6pnC6LLmqLUc/edit?usp=sharing\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUoImBZWzMxw"
      },
      "source": [
        "# import pandas as pd\n",
        "# !gdown --id \"1x_sQZc9z8cBg6NxmWVtCxjBuQ7Jkvry1\"\n",
        "# https://drive.google.com/file/d/1rRwZ-819_SBkjYNClAOpj_mhlYViMUtH/view?usp=sharing\n",
        "# https://drive.google.com/uc?id= OUR_FILE_ID &export=download\n",
        "# url2 = 'https://docs.google.com/uc?id=' + data2.split('/')[-2] + '&export=download'\n",
        "# url2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFE7hz2jTlrc",
        "outputId": "8d0813a9-3116-4375-977e-f1465925d938"
      },
      "source": [
        "# &export=download\n",
        "# url2 = \"https://drive.google.com/uc?id=\" + data2.split('/')[-2]\n",
        "# url2 = \"https://drive.goolge.com/uc?id='   +  data2.split('/')[-2]\n",
        "\n",
        "# df = pd.read_csv(data2, sep='\\t' ,parse_dates=[0],  names=['a','b','c','d', 'e'] )\n",
        "\n",
        "# df = pd.read_csv('https://cib.societegenerale.com/fileadmin/indices_feeds/CTA_Historical.xls',\n",
        "#                  sep='\\t',\n",
        "#                  parse_dates=[0],\n",
        "#                  names=['a','b','c','d', 'e'])\n",
        "\n",
        "# ,  error_bad_lines=False\n",
        "# import io\n",
        "# data = pd.read_csv(io.StringIO(data['iris-flower-dataset.csv'].decode('utf-8')))\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "sheet_name = 'UK'\n",
        "gsheetkey = \"1WtAQoXk0FpsyBfBCDN5k8ELGS6P22SZkFwe0SXD97Wo\"\n",
        "\n",
        "url=f'https://docs.google.com/spreadsheet/ccc?key={gsheetkey}&output=xlsx'\n",
        "df = pd.read_excel(url,sheet_name=sheet_name)\n",
        "print(df)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                CRIM                          ZN  INDUS  ...       B  LSTAT  MEDV\n",
            "0            0.00632                          18   2.31  ...  396.90   4.98  24.0\n",
            "1            0.02731                           0   7.07  ...  396.90   9.14  21.6\n",
            "2            0.02729                           0   7.07  ...  392.83   4.03  34.7\n",
            "3            0.03237                           0   2.18  ...  394.63   2.94  33.4\n",
            "4            0.06905                           0   2.18  ...  396.90   5.33  36.2\n",
            "...              ...                         ...    ...  ...     ...    ...   ...\n",
            "5014  UNITED KINGDOM                   ALCOA INC    NaN  ...     NaN    NaN   NaN\n",
            "5015  UNITED KINGDOM  THE REGARD PARTNERSHIP LTD    NaN  ...     NaN    NaN   NaN\n",
            "5016  UNITED KINGDOM        CORNING INCORPORATED    NaN  ...     NaN    NaN   NaN\n",
            "5017  UNITED KINGDOM       KONGSBERG GRUPPEN ASA    NaN  ...     NaN    NaN   NaN\n",
            "5018  UNITED KINGDOM                     BASF AG    NaN  ...     NaN    NaN   NaN\n",
            "\n",
            "[5019 rows x 14 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nV1jhumUPVxj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9369665-cce6-4f4f-f3eb-fd45fa46e667"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax',\n",
              "       'ptratio', 'bbtown', 'lstat', 'medv'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBx5TCezcQ9f"
      },
      "source": [
        "y = df[last_word_label].copy().values\n",
        "X = df.drop(last_word_label, axis = 1).values\n",
        "\n",
        "# X,y = df.iloc[:, :-1].values , df.iloc[:, -1].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22x7BUyQcRVH",
        "outputId": "cc621ae2-4deb-42b2-e43d-a82c17d78595"
      },
      "source": [
        "X,y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[6.00000e-03, 1.80000e+01, 2.31000e+00, ..., 1.53000e+01,\n",
              "         3.96898e+02, 4.98000e+00],\n",
              "        [2.70000e-02, 0.00000e+00, 7.07000e+00, ..., 1.78000e+01,\n",
              "         3.96898e+02, 9.14000e+00],\n",
              "        [2.70000e-02, 0.00000e+00, 7.07000e+00, ..., 1.78000e+01,\n",
              "         3.92828e+02, 4.03000e+00],\n",
              "        ...,\n",
              "        [6.10000e-02, 0.00000e+00, 1.19300e+01, ..., 2.10000e+01,\n",
              "         3.96898e+02, 5.64000e+00],\n",
              "        [1.10000e-01, 0.00000e+00, 1.19300e+01, ..., 2.10000e+01,\n",
              "         3.93449e+02, 6.48000e+00],\n",
              "        [4.70000e-02, 0.00000e+00, 1.19300e+01, ..., 2.10000e+01,\n",
              "         3.96898e+02, 7.88000e+00]]),\n",
              " array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
              "        18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
              "        15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
              "        13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
              "        21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
              "        35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
              "        19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
              "        20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
              "        23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
              "        33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
              "        21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
              "        20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
              "        23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
              "        15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
              "        17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
              "        25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
              "        23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
              "        32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
              "        34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
              "        20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
              "        26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
              "        31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
              "        22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
              "        42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
              "        36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
              "        32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
              "        20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
              "        20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
              "        22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
              "        21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
              "        19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
              "        32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
              "        18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
              "        16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
              "        13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
              "         7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
              "        12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
              "        27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
              "         8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
              "         9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
              "        10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
              "        15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
              "        19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
              "        29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
              "        20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
              "        23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9]))"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yjsc7Q0UD6M0"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test  = train_test_split(X,y, test_size = 0.2, random_state = 42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBgtgoJbECZm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1f9685a-b7f8-492b-edd5-6bab8923c9d0"
      },
      "source": [
        "if(regModelFlag == True):\n",
        "  svrModel.fit(X_train, y_train)\n",
        "  dtrModel.fit(X_train, y_train)\n",
        "  rfrModel.fit(X_train, y_train)\n",
        "  linMod.fit(X_train, y_train)\n",
        "\n",
        "  y_predLin = linMod.predict(X_test)\n",
        "  y_predSvr = svrModel.predict(X_test)\n",
        "  y_predDtr = dtrModel.predict(X_test)\n",
        "  y_predRfr = rfrModel.predict(X_test)\n",
        "\n",
        "  from sklearn.metrics import  mean_squared_error\n",
        "  print(\"Mean Squared Error: \\nlinear MSE : {}\\nsvr MSE : {}\\ndtr MSE : {}\\nrfr MSE : {}\\n\\n\"    .format(mean_squared_error(y_predLin, y_test), mean_squared_error(y_predSvr, y_test) , mean_squared_error(y_predDtr, y_test),\n",
        "                                                                             mean_squared_error(y_predRfr, y_test)))\n",
        "  \n",
        "  from sklearn.metrics import r2_score\n",
        "  print(\"r2 score: \\nlinear r2 : {}\\nsvr r2 : {}\\ndtr r2 : {}\\nrfr r2 : {}\"    .format(r2_score(y_predLin, y_test), r2_score(y_predSvr, y_test) , r2_score(y_predDtr, y_test),\n",
        "                                                                             r2_score(y_predRfr, y_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: \n",
            "linear MSE : 24.290463145792444\n",
            "svr MSE : 52.83835757091436\n",
            "dtr MSE : 8.713005965529616\n",
            "rfr MSE : 9.053695078431366\n",
            "\n",
            "\n",
            "r2 score: \n",
            "linear r2 : 0.633340580531289\n",
            "svr r2 : -2.6494943390329255\n",
            "dtr r2 : 0.846232958239387\n",
            "rfr r2 : 0.8501350215168549\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzDUAMDYfsVS"
      },
      "source": [
        "if(claModelFlag == True):\n",
        "  svcModel.fit(X_train, y_train)\n",
        "  # grid_svc.fit(X_train, y_train)\n",
        "  dtcModel.fit(X_train, y_train)\n",
        "  rfcModel.fit(X_train, y_train)\n",
        "  naiveModel.fit(X_train, y_train)\n",
        "  sgdModel.fit(X_train, y_train)\n",
        "  knnModel.fit(X_train, y_train)\n",
        "  # logModel.fit(X_train, y_train)\n",
        "\n",
        "  y_predSVC = svcModel.predict(X_test)\n",
        "  y_predDTC = dtcModel.predict(X_test)\n",
        "  y_predRFC = rfcModel.predict(X_test)\n",
        "  y_predNaiv =  naiveModel.predict(X_test)\n",
        "  y_predSGD = sgdModel.predict(X_test)\n",
        "  y_predKNN = knnModel.predict(X_test)\n",
        "  # # y_predLOG = logModel.predict(X_test)\n",
        "\n",
        "  from sklearn.metrics import  accuracy_score , confusion_matrix\n",
        "\n",
        "  print(\"SVC Model : \\naccuracy score : {}\\n confusion_matrix : \\n{}\\n\"  .format(accuracy_score(y_predSVC , y_test), confusion_matrix(y_predSVC , y_test)))\n",
        "  print(\"DTC Model : \\naccuracy score : {}\\n confusion_matrix : \\n{}\\n\"  .format(accuracy_score(y_predDTC , y_test), confusion_matrix(y_predDTC , y_test)))\n",
        "  print(\"RFC Model : \\naccuracy score : {}\\n confusion_matrix : \\n{}\\n\"  .format(accuracy_score(y_predRFC , y_test), confusion_matrix(y_predRFC , y_test)))\n",
        "  print(\"Naive Model : \\naccuracy score : {}\\n confusion_matrix : \\n{}\\n\"  .format(accuracy_score(y_predNaiv , y_test), confusion_matrix(y_predNaiv , y_test)))\n",
        "  print(\"SGD Model : \\naccuracy score : {}\\n confusion_matrix : \\n{}\\n\"  .format(accuracy_score(y_predSGD , y_test), confusion_matrix(y_predSGD , y_test)))\n",
        "  print(\"KNN Model : \\naccuracy score : {}\\n confusion_matrix : \\n{}\\n\"  .format(accuracy_score(y_predKNN , y_test), confusion_matrix(y_predKNN , y_test)))\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKESkU8FgktI"
      },
      "source": [
        "# from sklearn.metrics import  mean_squared_error\n",
        "# print(\"linear MSE : {}\\nsvr MSE : {}\\ndtr MSE : {}\\nrfr MSE : {}\"    .format(mean_squared_error(y_predLin, y_test), mean_squared_error(y_predSvr, y_test) , mean_squared_error(y_predDtr, y_test),\n",
        "#                                                                              mean_squared_error(y_predRfr, y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wY5QK-yhotg"
      },
      "source": [
        "# from sklearn.metrics import r2_score\n",
        "# print(\"linear r2 : {}\\nsvr r2 : {}\\ndtr r2 : {}\\nrfr r2 : {}\"    .format(r2_score(y_predLin, y_test), r2_score(y_predSvr, y_test) , r2_score(y_predDtr, y_test),\n",
        "#                                                                              r2_score(y_predRfr, y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzzCCy7pu02w"
      },
      "source": [
        "# !pip install -U -q PyDrive\n",
        "# from pydrive.auth import GoogleAuth\n",
        "# from pydrive.drive import GoogleDrive\n",
        "# from google.colab import auth\n",
        "# from oauth2client.client import GoogleCredentials\n",
        "# # Authenticate and create the PyDrive client.\n",
        "# auth.authenticate_user()\n",
        "# gauth = GoogleAuth()\n",
        "# gauth.credentials = GoogleCredentials.get_application_default()\n",
        "# drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9woxny6UsLs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}