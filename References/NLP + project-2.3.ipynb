{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.TextIOWrapper name='Machine learning3.1.txt' mode='r' encoding='cp1252'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open(\"Machine learning3.1.txt\", 'r', errors = 'ignore')\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw=f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am doing absolutely fine.....So what is your query for today?\\nHi, Good to hear from you.....So whats your query today?\\n\\nOh great, so you have come at the right place to process your dataset.\\n\\nWonderful , but can you tell me which specific machine learning algorithm type, classification or regression?\\n\\nWonderful , but can you tell me which specific ML algorithm you would like to run, classification or regression. \\n\\nGreat , So which classification algorithm?\\nGreat, So which regression algorithm?\\n\\n\\nWhat would be the label of the dataset?\\nthe label of the dataset would be ___________\\n\\nSo the label of the dataset would be ____________\\n\\n\\n\\nThanks for the link, now may I know the label or the target column?\\n\\nSo ______ would be your label/target column... thank you for providing all the data... now just sit back and enjoy the magic of ML.\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw=raw.lower()# converts to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_tokens = nltk.sent_tokenize(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i am doing absolutely fine.....so what is your query for today?',\n",
       " 'hi, good to hear from you.....so whats your query today?']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokens[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokens = nltk.word_tokenize(raw)# converts to list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'am', 'doing', 'absolutely', 'fine']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokens[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i am doing absolutely fine.....so what is your query for today?',\n",
       " 'hi, good to hear from you.....so whats your query today?',\n",
       " 'oh great, so you have come at the right place to process your dataset.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokens[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'am', 'doing', 'absolutely', 'fine']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokens[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmer = nltk.stem.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LemTokens(tokens):\n",
    "    return [lemmer.lemmatize(token) for token in tokens]\n",
    "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LemNormalize(text):\n",
    "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "GREETING_INPUTS = (\"hello\", \"hi\", \"greetings\", \"sup\", \"what's up\",\"hey\",)\n",
    "GREETING_RESPONSES = [\"hi\", \"hey\",  \"hi there\", \"hello\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "REGRESSION_INPUTS = ['Linear Regression', 'Decision Tree' , 'Support Vector Regression ','Lasso Regression','Ridge Regression',\n",
    "                      'Random Forest Regression']\n",
    "\n",
    "CLASSIFICATION_INPUTS  = ['Logistic Regression','Naive Bayes','Stochastic Gradient Descent','K-Nearest Neighbours',\n",
    "                         'Decision Tree', 'Random Forest', 'Support Vector Machine']\n",
    "\n",
    "DEEPLEARNING_INPUTS = ['Convolutional Neural Network','Long Short Term Memory Networks (LSTMs)',\n",
    "                       'Recurrent Neural Networks (RNNs)', 'BERT', 'Transfer Learning']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greeting(sentence):\n",
    "    \"\"\"If user's input is a greeting, return a greeting response\"\"\"\n",
    "    for word in sentence.split():\n",
    "        if word.lower() in GREETING_INPUTS:\n",
    "            return random.choice(GREETING_RESPONSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of regression list is:  6\n"
     ]
    }
   ],
   "source": [
    "def regAlgorithm(sentence):\n",
    "#     r = re.compile(\".*{}.*\" .format(sentence))\n",
    "#     matchedStr = str(filter(r.match, REGRESSION_INPUTS)) # Read Note below\n",
    "#     print(matchedStr)\n",
    "    count = 1\n",
    "    for pattern in REGRESSION_INPUTS:\n",
    "        \n",
    "        if count <= len(REGRESSION_INPUTS):\n",
    "        \n",
    "            if re.search(pattern.lower(), sentence):\n",
    "                    Robo_response = pattern + \" thats wonderful, Now may I know the target label for your dataset\"\n",
    "                    return Robo_response\n",
    "                    \n",
    "#             else:\n",
    "#                     if count == len(REGRESSION_INPUTS):\n",
    "#                           return \"Could you be more specific!\" \n",
    "                        \n",
    "                    count = count+1\n",
    "                    \n",
    "print(\"length of regression list is: \" ,len(REGRESSION_INPUTS))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of regression list is:  7\n"
     ]
    }
   ],
   "source": [
    "def claAlgorithm(sentence):\n",
    "#     r = re.compile(\".*{}.*\" .format(sentence))\n",
    "#     matchedStr = str(filter(r.match, REGRESSION_INPUTS)) # Read Note below\n",
    "#     print(matchedStr)\n",
    "    count = 1\n",
    "    for pattern in CLASSIFICATION_INPUTS:\n",
    "        \n",
    "        if count <= len(CLASSIFICATION_INPUTS):\n",
    "        \n",
    "            if re.search(pattern.lower(), sentence):\n",
    "                    Robo_response = \"So you want to run \" + pattern\n",
    "                    return Robo_response\n",
    "                    \n",
    "#             else:\n",
    "#                     if count == len(REGRESSION_INPUTS):\n",
    "#                           return \"Could you be more specific!\" \n",
    "                        \n",
    "                    count = count+1\n",
    "                    \n",
    "print(\"length of regression list is: \" ,len(CLASSIFICATION_INPUTS))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of regression list is:  5\n"
     ]
    }
   ],
   "source": [
    "def deepAlgorithm(sentence):\n",
    "#     r = re.compile(\".*{}.*\" .format(sentence))\n",
    "#     matchedStr = str(filter(r.match, REGRESSION_INPUTS)) # Read Note below\n",
    "#     print(matchedStr)\n",
    "    count = 1\n",
    "    for pattern in DEEPLEARNING_INPUTS:\n",
    "        \n",
    "        if count <= len(DEEPLEARNING_INPUTS):\n",
    "        \n",
    "            if re.search(pattern.lower(), sentence):\n",
    "                    Robo_response = \"So you want to run \" + pattern\n",
    "                    return Robo_response\n",
    "                    \n",
    "#             else:\n",
    "#                     if count == len(REGRESSION_INPUTS):\n",
    "#                           return \"Could you be more specific!\" \n",
    "                        \n",
    "                    count = count+1\n",
    "                    \n",
    "print(\"length of regression list is: \" ,len(DEEPLEARNING_INPUTS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def response(user_response):\n",
    "    robo_response=''\n",
    "    TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')\n",
    "    tfidf = TfidfVec.fit_transform(sent_tokens)\n",
    "    vals = cosine_similarity(tfidf[-1], tfidf)\n",
    "    idx=vals.argsort()[0][-2]\n",
    "    flat = vals.flatten()\n",
    "    flat.sort()\n",
    "    req_tfidf = flat[-2]\n",
    "    if(req_tfidf==0):\n",
    "        robo_response=robo_response+\"I am sorry! I don't understand you, be more elaborative\"\n",
    "        return robo_response\n",
    "    else:\n",
    "        robo_response = robo_response+sent_tokens[idx]\n",
    "        return robo_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROBO: My name is Robo. I will answer your queries about Chatbots. If you want to exit, type Bye!\n",
      "hi\n",
      "ROBO: hi\n",
      "how are you doing\n",
      "ROBO: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda4\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i am doing absolutely fine.....so what is your query for today?\n",
      "nothin much I want to run a few ML algorithms\n",
      "ROBO: wonderful , but can you tell me which specific ml algorithm you would like to run, classification or regression.\n",
      "regression\n",
      "ROBO: great, so which regression algorithm?\n",
      "Lasso Regression algo\n",
      "ROBO:  Lasso Regression thats wonderful, Now may I know the target label for your dataset\n",
      "ya its purchased\n",
      "ROBO: So purchased would be your target/label , seems good, now can you provide me link for the dataset\n",
      "ya sure! its https://sdfsfsfsfsf\n",
      "Thanks for the link https://sdfsfsfsfsf, Do you want to do anymore preprocessing on the data\n",
      "bye\n",
      "ROBO: Bye! take care..\n"
     ]
    }
   ],
   "source": [
    "flag=True\n",
    "regAlgo = False\n",
    "linkFlag = False\n",
    "\n",
    "print(\"ROBO: My name is Robo. I will answer your queries about Chatbots. If you want to exit, type Bye!\")\n",
    "\n",
    "while(flag==True):\n",
    "    \n",
    "    user_response = input()\n",
    "    \n",
    "    user_response=user_response.lower()\n",
    "    \n",
    "    \n",
    "    \n",
    "    if(user_response!='bye'):\n",
    "#         if(user_response=='thanks' or user_response=='thank you' ):\n",
    "#             flag=False\n",
    "#             print(\"ROBO: You are welcome..\")\n",
    "#         else:\n",
    "            \n",
    "    \n",
    "            if(greeting(user_response)!=None):\n",
    "                \n",
    "                print(\"ROBO: \"+greeting(user_response))\n",
    "                \n",
    "            \n",
    "            elif(linkFlag == True):\n",
    "                \n",
    "                link_use_resp = user_response\n",
    "                \n",
    "                pattern_link = r'https://.*'\n",
    "\n",
    "                for final_link in link_use_resp.split():\n",
    "                     \n",
    "                        if re.search(pattern_link, final_link):\n",
    "                \n",
    "                            print(\"Thanks for the link {}, Do you want to do anymore preprocessing on the data\" .format(final_link))\n",
    "                            linkFlag = False\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "            elif(regAlgo == True):\n",
    "                \n",
    "                w = []\n",
    "                for word in user_response.split():\n",
    "                    w.append(word)\n",
    "                    last_word_label = w[len(w)-1]\n",
    "                \n",
    "                print(\"ROBO: So {} would be your target/label , seems good, now can you provide me link for the dataset\" \n",
    "                      .format(last_word_label)) \n",
    "                \n",
    "                regAlgo = False\n",
    "            \n",
    "                linkFlag = True \n",
    "            \n",
    "                \n",
    "            \n",
    "            elif(regAlgorithm(user_response) != None) :\n",
    "                \n",
    "                   \n",
    "                \n",
    "                    robo_response = regAlgorithm(user_response)\n",
    "                    regAlgo = True\n",
    "                    \n",
    "        \n",
    "                    print(\"ROBO: \", robo_response)\n",
    "            \n",
    "                    \n",
    "            \n",
    "#                     sent_tokens.append(user_response)\n",
    "\n",
    "#                     word_tokens=word_tokens + nltk.word_tokenize(user_response)\n",
    "\n",
    "#                     final_words=list(set(word_tokens))\n",
    "\n",
    "#                     print(\"ROBO: \",end=\"\")\n",
    "\n",
    "                    \n",
    "\n",
    "#                     sent_tokens.remove(user_response)\n",
    "                    \n",
    "            elif(claAlgorithm(user_response) != None) :\n",
    "                    \n",
    "                    print(\"ROBO: \" +claAlgorithm(user_response))\n",
    "            else:    \n",
    "                \n",
    "                    sent_tokens.append(user_response)\n",
    "\n",
    "                    word_tokens=word_tokens+nltk.word_tokenize(user_response)\n",
    "\n",
    "                    final_words=list(set(word_tokens))\n",
    "\n",
    "                    print(\"ROBO: \",end=\"\")\n",
    "\n",
    "                    print(response(user_response))\n",
    "\n",
    "                    sent_tokens.remove(user_response)\n",
    "    else:\n",
    "        flag=False\n",
    "        print(\"ROBO: Bye! take care..\")    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x for x in list if r.match(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
